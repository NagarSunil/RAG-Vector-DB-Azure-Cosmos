{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945e13fa-5c64-4ec6-9ad7-7213d2a9812c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting azure-cosmos\n",
      "  Downloading azure_cosmos-4.9.0-py3-none-any.whl.metadata (80 kB)\n",
      "     ---------------------------------------- 0.0/80.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/80.8 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 30.7/80.8 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------------ ------------- 51.2/80.8 kB 660.6 kB/s eta 0:00:01\n",
      "     ------------------------ ------------- 51.2/80.8 kB 660.6 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 71.7/80.8 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 80.8/80.8 kB 410.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: fastapi in c:\\users\\sunil\\anaconda3\\lib\\site-packages (0.115.6)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sunil\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sunil\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from openai) (0.26.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Collecting azure-core>=1.30.0 (from azure-cosmos)\n",
      "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from fastapi) (0.41.3)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from azure-core>=1.30.0->azure-cosmos) (2.32.2)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from azure-core>=1.30.0->azure-cosmos) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-cosmos) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sunil\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-cosmos) (1.26.20)\n",
      "Downloading openai-1.57.4-py3-none-any.whl (390 kB)\n",
      "   ---------------------------------------- 0.0/390.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 390.3/390.3 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading azure_cosmos-4.9.0-py3-none-any.whl (303 kB)\n",
      "   ---------------------------------------- 0.0/303.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 303.2/303.2 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.3/62.3 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "   ---------------------------------------- 0.0/198.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 198.9/198.9 kB 12.6 MB/s eta 0:00:00\n",
      "Downloading jiter-0.8.2-cp312-cp312-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 204.7/204.7 kB 13.0 MB/s eta 0:00:00\n",
      "Installing collected packages: jiter, uvicorn, azure-core, openai, azure-cosmos\n",
      "Successfully installed azure-core-1.32.0 azure-cosmos-4.9.0 jiter-0.8.2 openai-1.57.4 uvicorn-0.34.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai azure-cosmos fastapi uvicorn numpy python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2663e2-c8da-4e33-8507-6e99ac112d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY=your_openai_api_key\n",
    "AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT=your-embedding-deployment-name\n",
    "AZURE_COSMOS_URL=https://your-cosmosdb.documents.azure.com:443/\n",
    "AZURE_COSMOS_KEY=your-cosmosdb-primary-key\n",
    "DATABASE_NAME=vector_db\n",
    "CONTAINER_NAME=embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56989c2-4e60-4292-9075-a3811d0a7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from azure.cosmos import CosmosClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI Configuration\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2024-05-01-preview\"\n",
    "\n",
    "# Cosmos DB Configuration\n",
    "cosmos_url = os.getenv(\"AZURE_COSMOS_URL\")\n",
    "cosmos_key = os.getenv(\"AZURE_COSMOS_KEY\")\n",
    "database_name = os.getenv(\"DATABASE_NAME\")\n",
    "container_name = os.getenv(\"CONTAINER_NAME\")\n",
    "\n",
    "# Initialize Cosmos DB client\n",
    "cosmos_client = CosmosClient(cosmos_url, cosmos_key)\n",
    "database = cosmos_client.create_database_if_not_exists(id=database_name)\n",
    "container = database.create_container_if_not_exists(id=container_name, partition_key=\"/id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce91988-c0e6-494c-afd8-0f762c0f48df",
   "metadata": {},
   "source": [
    "Generate and Store Embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f3f09-9bcd-44f4-b8b3-f1af78c086e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts):\n",
    "    \"\"\"\n",
    "    Generate embeddings using Azure OpenAI's embedding model.\n",
    "    \"\"\"\n",
    "    response = openai.Embedding.create(\n",
    "        input=texts,\n",
    "        engine=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "    )\n",
    "    return [data['embedding'] for data in response['data']]\n",
    "\n",
    "def store_embeddings(texts):\n",
    "    \"\"\"\n",
    "    Store documents and embeddings in Cosmos DB.\n",
    "    \"\"\"\n",
    "    embeddings = generate_embeddings(texts)\n",
    "    for i, (text, embedding) in enumerate(zip(texts, embeddings)):\n",
    "        container.upsert_item({\n",
    "            \"id\": str(i),\n",
    "            \"text\": text,\n",
    "            \"embedding\": embedding\n",
    "        })\n",
    "    print(\"Embeddings stored successfully.\")\n",
    "\n",
    "# Example texts\n",
    "documents = [\n",
    "    \"Azure OpenAI provides GPT models for text generation.\",\n",
    "    \"Cosmos DB is a globally distributed NoSQL database.\",\n",
    "    \"Retrieval-Augmented Generation enhances AI applications.\"\n",
    "]\n",
    "\n",
    "# Store embeddings\n",
    "store_embeddings(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e984473-05ff-40b8-8d1d-7d113e618c60",
   "metadata": {},
   "source": [
    "Query for Similar Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d34bdb-8d62-4e95-a93c-545c7e96cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two vectors.\n",
    "    \"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def query_similar_documents(query, top_k=2):\n",
    "    \"\"\"\n",
    "    Query for the most similar documents based on embeddings.\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = generate_embeddings([query])[0]\n",
    "    \n",
    "    # Retrieve all items from Cosmos DB\n",
    "    query_results = container.query_items(\"SELECT * FROM embeddings\", enable_cross_partition_query=True)\n",
    "    \n",
    "    # Calculate similarity\n",
    "    similarities = []\n",
    "    for item in query_results:\n",
    "        stored_embedding = np.array(item['embedding'])\n",
    "        similarity = cosine_similarity(query_embedding, stored_embedding)\n",
    "        similarities.append((item['text'], similarity))\n",
    "    \n",
    "    # Sort and return top-k documents\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_k]\n",
    "\n",
    "# Query example\n",
    "query_text = \"How does RAG improve AI responses?\"\n",
    "results = query_similar_documents(query_text)\n",
    "print(\"Top relevant documents:\", results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51156204-b9ff-46e3-8cf1-acba5e441ea5",
   "metadata": {},
   "source": [
    " Build a FastAPI Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334b5e8-d460-4c9e-9889-a7bf0587c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Request body schemas\n",
    "class StoreRequest(BaseModel):\n",
    "    texts: list\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "\n",
    "@app.post(\"/store\")\n",
    "def store_texts(request: StoreRequest):\n",
    "    \"\"\"\n",
    "    Endpoint to store text embeddings.\n",
    "    \"\"\"\n",
    "    store_embeddings(request.texts)\n",
    "    return {\"message\": \"Documents stored successfully.\"}\n",
    "\n",
    "@app.post(\"/query\")\n",
    "def query_text(request: QueryRequest):\n",
    "    \"\"\"\n",
    "    Endpoint to query similar documents and return GPT response.\n",
    "    \"\"\"\n",
    "    # Retrieve top relevant documents\n",
    "    top_docs = query_similar_documents(request.query)\n",
    "    context = \"\\n\".join([doc[0] for doc in top_docs])\n",
    "    \n",
    "    # Generate response using GPT model\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {request.query}\\nAnswer:\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-4\",  # Your GPT deployment\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return {\"response\": response['choices'][0]['message']['content']}\n",
    "\n",
    "# Run the FastAPI app\n",
    "# Command: uvicorn app:app --reload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15160b6-c32d-4743-a9bb-cdba5a89e050",
   "metadata": {},
   "source": [
    "Test the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4187ba-31fe-4532-8c32-0df5949586f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvicorn app:app --reload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65fd3f9-2daf-4dbe-88bc-fbb3c319b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test Endpoints:\n",
    "\n",
    "        Store Documents\n",
    "POST http://127.0.0.1:8000/store\n",
    "Content-Type: application/json\n",
    "\n",
    "{\n",
    "  \"texts\": [\"Azure OpenAI generates embeddings\", \"Cosmos DB stores vectors efficiently\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c278f-f4fd-4db4-b05b-8391031648b6",
   "metadata": {},
   "source": [
    "Query Documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f62a2-8d0f-4d73-bfd5-aa2809b42274",
   "metadata": {},
   "outputs": [],
   "source": [
    "POST http://127.0.0.1:8000/query\n",
    "Content-Type: application/json\n",
    "\n",
    "{\n",
    "  \"query\": \"How does Cosmos DB store embeddings?\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a09d73d5-dd02-4d7b-a557-4e64ea21f30c",
   "metadata": {},
   "source": [
    "Summary of Workflow\n",
    "Azure OpenAI generates embeddings for text.\n",
    "Cosmos DB stores these embeddings along with the text.\n",
    "FastAPI provides RESTful endpoints to store new documents, query relevant documents, and generate GPT-based responses.\n",
    "RAG Pipeline combines document retrieval and GPT to produce accurate, context-aware answers.\n",
    "This approach ensures efficient and scalable implementation for RAG applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b0ec8-0333-4cdf-93dd-2afccd30f77f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
